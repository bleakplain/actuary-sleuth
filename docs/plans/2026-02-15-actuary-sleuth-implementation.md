# Actuary Sleuth Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build an insurance product compliance audit system using SKILL.md workflow orchestration with Python scripts, integrating SQLite, LanceDB vector search, and Ollama LLM for automated regulatory checking.

**Architecture:** Feishu Channel receives user messages â†’ parses SKILL.md â†’ calls Python scripts â†’ scripts interact with SQLite/LanceDB/Ollama â†’ return structured audit reports.

**Tech Stack:** Python 3.10+, SQLite, LanceDB, Ollama (qwen2:7b, nomic-embed-text), feishu2md, PaddleOCR

---

## Task 1: Create Project Structure

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/SKILL.md`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/skill.json`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/template.py`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/__init__.py`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/config/settings.json`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/requirements.txt`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/data/.gitkeep`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/references/.gitkeep`

**Step 1: Create SKILL.md**

Run: `mkdir -p /root/.openclaw/workspace/skills/actuary-sleuth`

```markdown
---
name: actuary-sleuth
description: Use when reviewing insurance product clauses for compliance, checking against regulatory negative lists, calculating pricing reasonableness, or querying insurance regulations and laws. Use forç²¾ç®—å¸ˆæ—¥å¸¸è¯„å®¡å·¥ä½œ includingæ–°äº§å“æ¡æ¬¾å®¡æ ¸ã€æ³•è§„æŸ¥è¯¢ã€è´Ÿé¢æ¸…å•æ£€æŸ¥ã€å®šä»·åˆç†æ€§è®¡ç®—å’Œè¯„å®¡æŠ¥å‘Šç”Ÿæˆ.
metadata:
  openclaw:
    emoji: "ğŸ“Š"
    requires:
      bins: ["python3"]
---

# Actuary Sleuth - ç²¾ç®—å®¡è®¡åŠ©æ‰‹

## Overview

é¢å‘ç²¾ç®—å¸ˆçš„ä¸“ä¸šäº§å“è¯„å®¡è¾…åŠ©ç³»ç»Ÿï¼Œå¸®åŠ©ç²¾ç®—å¸ˆæ›´é«˜æ•ˆåœ°è¯„å®¡ä¿é™©äº§å“æ¡æ¬¾ã€‚

## Tools

### audit_document
å®¡æ ¸ä¿é™©äº§å“æ–‡æ¡£

**Input:**
- documentContent (string): Markdownæ ¼å¼çš„æ–‡æ¡£å†…å®¹
- documentUrl (string): æ–‡æ¡£URLï¼ˆå¯é€‰ï¼‰
- auditType (string): å®¡æ ¸ç±»å‹ï¼Œfull/negative-onlyï¼ˆå¯é€‰ï¼Œé»˜è®¤fullï¼‰

**Output:**
```json
{
  "success": true,
  "violations": [...],
  "pricing": {...},
  "score": 75,
  "report": "..."
}
```

### query_regulation
æŸ¥è¯¢ä¿é™©æ³•è§„

**Input:**
- query (string): æŸ¥è¯¢è¯
- searchType (string): exact/semantic/hybridï¼ˆå¯é€‰ï¼Œé»˜è®¤hybridï¼‰

**Output:**
```json
{
  "success": true,
  "results": [...]
}
```

### check_negative_list
æ£€æŸ¥è´Ÿé¢æ¸…å•

**Input:**
- clauses (array): äº§å“æ¡æ¬¾æ•°ç»„

**Output:**
```json
{
  "success": true,
  "violations": [...]
}
```
```

**Step 2: Create skill.json**

```json
{
  "id": "actuary-sleuth",
  "name": "Actuary Sleuth",
  "version": "3.0.0",
  "readme": "SKILL.md",
  "config": {
    "scriptsPath": "./scripts",
    "dataPath": "./data",
    "pythonEnv": "python3",
    "lancedbUri": "./data/lancedb",
    "ollamaHost": "http://localhost:11434",
    "ollamaModel": "qwen2:7b",
    "ollamaEmbedModel": "nomic-embed-text"
  }
}
```

**Step 3: Create template.py**

Run: `mkdir -p /root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Actuary Sleuth Script Template
ç»Ÿä¸€è„šæœ¬æ¥å£è§„èŒƒ
"""
import argparse
import json
import sys
from pathlib import Path

# æ·»åŠ  lib ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'lib'))

def main():
    parser = argparse.ArgumentParser(description='Actuary Sleuth Script')
    parser.add_argument('--input', required=True, help='JSON input file')
    parser.add_argument('--config', default='./config/settings.json', help='Config file')
    args = parser.parse_args()

    # è¯»å–è¾“å…¥
    with open(args.input, 'r', encoding='utf-8') as f:
        params = json.load(f)

    # æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    try:
        result = execute(params)
        # è¾“å‡ºç»“æœï¼ˆJSONæ ¼å¼ï¼‰
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return 0
    except Exception as e:
        # é”™è¯¯è¾“å‡º
        error_result = {
            "success": False,
            "error": str(e),
            "error_type": type(e).__name__
        }
        print(json.dumps(error_result, ensure_ascii=False), file=sys.stderr)
        return 1

def execute(params):
    """å…·ä½“ä¸šåŠ¡é€»è¾‘å®ç° - å­ç±»å¿…é¡»è¦†ç›–"""
    raise NotImplementedError("Subclasses must implement execute()")

if __name__ == '__main__':
    sys.exit(main())
```

**Step 4: Create lib/__init__.py**

Run: `touch /root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/__init__.py`

```python
# Actuary Sleuth Library
```

**Step 5: Create config/settings.json**

Run: `mkdir -p /root/.openclaw/workspace/skills/actuary-sleuth/scripts/config`

```json
{
  "scriptsPath": "./scripts",
  "dataPath": "./data",
  "pythonEnv": "python3",
  "lancedbUri": "./data/lancedb",
  "ollamaHost": "http://localhost:11434",
  "ollamaModel": "qwen2:7b",
  "ollamaEmbedModel": "nomic-embed-text"
}
```

**Step 6: Create requirements.txt**

```
lancedb>=0.5.0
requests>=2.28.0
pyarrow>=14.0.0
paddleocr>=2.7.0
```

**Step 7: Create data and references directories**

Run: `mkdir -p /root/.openclaw/workspace/skills/actuary-sleuth/data /root/.openclaw/workspace/skills/actuary-sleuth/references`

Run: `touch /root/.openclaw/workspace/skills/actuary-sleuth/data/.gitkeep /root/.openclaw/workspace/skills/actuary-sleuth/references/.gitkeep`

**Step 8: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/`

Run: `git commit -m "feat: create actuary-sleuth skill base structure"`

---

## Task 2: Implement Database Module (lib/db.py)

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/db.py`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/init_db.py`
- Test: Create test file manually for validation

**Step 1: Write lib/db.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ“ä½œæ¨¡å—
"""
import sqlite3
import json
from pathlib import Path

DB_PATH = Path(__file__).parent.parent.parent / 'data' / 'actuary.db'

def get_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def find_regulation(article_number):
    """ç²¾ç¡®æŸ¥æ‰¾æ³•è§„æ¡æ¬¾"""
    conn = get_connection()
    cur = conn.cursor()

    cur.execute('''
        SELECT * FROM regulations
        WHERE article_number = ?
    ''', (article_number,))

    row = cur.fetchone()
    conn.close()

    if row:
        return dict(row)
    return None

def search_regulations(keyword):
    """å…³é”®è¯æœç´¢æ³•è§„"""
    conn = get_connection()
    cur = conn.cursor()

    cur.execute('''
        SELECT * FROM regulations
        WHERE content LIKE ? OR article_number LIKE ?
        LIMIT 20
    ''', (f'%{keyword}%', f'%{keyword}%'))

    rows = cur.fetchall()
    conn.close()

    return [dict(row) for row in rows]

def get_negative_list():
    """è·å–è´Ÿé¢æ¸…å•"""
    conn = get_connection()
    cur = conn.cursor()

    cur.execute('SELECT * FROM negative_list ORDER BY severity DESC')
    rows = cur.fetchall()
    conn.close()

    return [dict(row) for row in rows]

def save_audit_record(record):
    """ä¿å­˜å®¡æ ¸è®°å½•"""
    conn = get_connection()
    cur = conn.cursor()

    cur.execute('''
        INSERT INTO audit_history (id, user_id, document_url, violations, score)
        VALUES (?, ?, ?, ?, ?)
    ''', (
        record['id'],
        record.get('user_id', ''),
        record.get('document_url', ''),
        json.dumps(record.get('violations', []), ensure_ascii=False),
        record.get('score', 0)
    ))

    conn.commit()
    conn.close()
```

**Step 2: Write init_db.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆå§‹åŒ–æ•°æ®åº“
"""
import sqlite3
from pathlib import Path

DB_PATH = Path(__file__).parent.parent / 'data' / 'actuary.db'

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    conn = sqlite3.connect(DB_PATH)

    # åˆ›å»ºæ³•è§„è¡¨
    conn.execute('''
        CREATE TABLE IF NOT EXISTS regulations (
            id TEXT PRIMARY KEY,
            law_name TEXT NOT NULL,
            article_number TEXT,
            content TEXT NOT NULL,
            category TEXT,
            tags TEXT,
            effective_date TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.execute('''
        CREATE INDEX IF NOT EXISTS idx_article
        ON regulations(law_name, article_number)
    ''')

    # åˆ›å»ºè´Ÿé¢æ¸…å•è¡¨
    conn.execute('''
        CREATE TABLE IF NOT EXISTS negative_list (
            id INTEGER PRIMARY KEY,
            rule_number TEXT UNIQUE,
            description TEXT NOT NULL,
            severity TEXT,
            category TEXT,
            remediation TEXT,
            keywords TEXT,
            patterns TEXT,
            version TEXT,
            effective_date TEXT
        )
    ''')

    # åˆ›å»ºå®¡æ ¸å†å²è¡¨
    conn.execute('''
        CREATE TABLE IF NOT EXISTS audit_history (
            id TEXT PRIMARY KEY,
            user_id TEXT,
            document_url TEXT,
            document_type TEXT,
            violations TEXT,
            score REAL,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    conn.commit()
    conn.close()
    print(f"Database initialized: {DB_PATH}")

if __name__ == '__main__':
    init_database()
```

**Step 3: Make executable and test**

Run: `chmod +x /root/.openclaw/workspace/skills/actuary-sleuth/scripts/init_db.py`

Run: `cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/init_db.py`

Expected: `Database initialized: /root/.openclaw/workspace/skills/actuary-sleuth/data/actuary.db`

Run: `sqlite3 /root/.openclaw/workspace/skills/actuary-sleuth/data/actuary.db ".tables"`

Expected: `audit_history  negative_list  regulations`

**Step 4: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/`

Run: `git commit -m "feat: implement database module and initialization script"`

---

## Task 3: Implement Ollama Module (lib/ollama.py)

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/ollama.py`

**Step 1: Write lib/ollama.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM è°ƒç”¨æ¨¡å—
"""
import requests
import json

OLLAMA_HOST = 'http://localhost:11434'
EMBED_MODEL = 'nomic-embed-text'
CHAT_MODEL = 'qwen2:7b'

def embed(text):
    """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
    try:
        response = requests.post(
            f'{OLLAMA_HOST}/api/embeddings',
            json={
                'model': EMBED_MODEL,
                'prompt': text
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()['embedding']
    except Exception as e:
        raise Exception(f"Ollama embed error: {str(e)}")

def generate(prompt, system=None):
    """ç”Ÿæˆæ–‡æœ¬"""
    data = {
        'model': CHAT_MODEL,
        'prompt': prompt,
        'stream': False
    }

    if system:
        data['system'] = system

    try:
        response = requests.post(
            f'{OLLAMA_HOST}/api/generate',
            json=data,
            timeout=120
        )
        response.raise_for_status()
        return response.json()['response']
    except Exception as e:
        raise Exception(f"Ollama generate error: {str(e)}")

def analyze_compliance(clause, regulations):
    """åˆ†ææ¡æ¬¾åˆè§„æ€§"""
    prompt = f"""ä½œä¸ºä¿é™©ç²¾ç®—ä¸“å®¶ï¼Œè¯·åˆ¤æ–­ä»¥ä¸‹æ¡æ¬¾æ˜¯å¦è¿è§„ï¼š

ã€æ¡æ¬¾å†…å®¹ã€‘
{clause}

ã€ç›¸å…³æ³•è§„ã€‘
{chr(10).join(regulations[:3])}

è¯·è¿”å›JSONæ ¼å¼ï¼ˆä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "is_violation": trueæˆ–false,
    "reason": "è¿è§„åŸå› æˆ–åˆè§„è¯´æ˜",
    "severity": "highæˆ–mediumæˆ–low",
    "suggestion": "æ•´æ”¹å»ºè®®"
}}"""

    try:
        result = generate(prompt)
        # å°è¯•è§£æ JSON
        result = result.strip()
        if result.startswith('```'):
            result = result.split('\n', 1)[1]
        if result.endswith('```'):
            result = result.rsplit('\n', 1)[0]
        if result.startswith('json'):
            result = result[4:]

        return json.loads(result)
    except:
        # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
        return {
            "is_violation": False,
            "reason": "æ— æ³•è§£æ",
            "severity": "low",
            "suggestion": "è¯·äººå·¥å¤æ ¸"
        }
```

**Step 2: Test Ollama connection**

Run: `curl -s http://localhost:11434/api/tags | head -20`

Expected: Ollama model list (if running)

**Step 3: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/ollama.py`

Run: `git commit -m "feat: implement ollama LLM integration module"`

---

## Task 4: Implement LanceDB Module (lib/lancedb.py)

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/lancedb.py`

**Step 1: Write lib/lancedb.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘é‡æ£€ç´¢æ¨¡å—
"""
import lancedb
from pathlib import Path

DB_URI = str(Path(__file__).parent.parent.parent / 'data' / 'lancedb')

class VectorDB:
    _instance = None
    _tables = {}

    @classmethod
    def connect(cls):
        """è¿æ¥ LanceDB"""
        if cls._instance is None:
            cls._instance = lancedb.connect(DB_URI)
        return cls._instance

    @classmethod
    def get_table(cls, table_name='regulations_vectors'):
        """è·å–è¡¨"""
        if table_name not in cls._tables:
            db = cls.connect()
            try:
                cls._tables[table_name] = db.open_table(table_name)
            except:
                return None
        return cls._tables[table_name]

    @classmethod
    def search(cls, query_vector, top_k=5, table_name='regulations_vectors'):
        """å‘é‡æœç´¢"""
        table = cls.get_table(table_name)
        if table is None:
            return []

        results = table.vectorSearch(query_vector).limit(top_k).to_pydict()

        return [
            {
                'content': r['chunk_text'],
                'metadata': r['metadata'],
                'score': 1 / (1 + r.get('_distance', 0))
            }
            for r in results
        ]

    @classmethod
    def add_vectors(cls, data, table_name='regulations_vectors'):
        """æ·»åŠ å‘é‡"""
        db = cls.connect()

        existing_tables = db.table_names()
        if table_name not in existing_tables:
            import pyarrow as pa
            schema = pa.schema([
                pa.field('id', pa.string()),
                pa.field('regulation_id', pa.string()),
                pa.field('chunk_text', pa.string()),
                pa.field('vector', pa.list_(pa.float32())),
                pa.field('metadata', pa.string())
            ])
            table = db.create_table(table_name, schema=schema)
        else:
            table = db.open_table(table_name)

        table.add(data)
        cls._tables[table_name] = table
```

**Step 2: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/lib/lancedb.py`

Run: `git commit -m "feat: implement LanceDB vector search module"`

---

## Task 5: Implement Query Script (scripts/query.py)

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/query.py`

**Step 1: Write query.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³•è§„æŸ¥è¯¢è„šæœ¬
"""
from template import main
from lib import db, lancedb, ollama

def execute(params):
    """æ‰§è¡Œæ³•è§„æŸ¥è¯¢"""
    query_text = params['query']
    search_type = params.get('searchType', 'hybrid')

    results = []

    # ç²¾ç¡®æŸ¥è¯¢
    if search_type in ['exact', 'hybrid']:
        exact = db.find_regulation(query_text)
        if exact:
            results.append({
                'type': 'exact',
                'content': exact['content'],
                'law_name': exact['law_name'],
                'article_number': exact['article_number'],
                'category': exact['category'],
                'score': 1.0
            })

    # è¯­ä¹‰æ£€ç´¢
    if search_type in ['semantic', 'hybrid']:
        query_vec = ollama.embed(query_text)
        semantic = lancedb.VectorDB.search(query_vec, top_k=5)
        for item in semantic:
            results.append({
                'type': 'semantic',
                'content': item['content'],
                'law_name': item['metadata']['law_name'],
                'article_number': item['metadata']['article_number'],
                'score': item['score']
            })

    # æ’åºè¿”å›
    results.sort(key=lambda x: x['score'], reverse=True)

    return {
        'success': True,
        'query': query_text,
        'search_type': search_type,
        'results': results[:5],
        'count': len(results[:5])
    }

if __name__ == '__main__':
    main()
```

**Step 2: Make executable and test**

Run: `chmod +x /root/.openclaw/workspace/skills/actuary-sleuth/scripts/query.py`

Run: `echo '{"query":"ä¿é™©æ³•ç¬¬åå…­æ¡"}' > /tmp/test_query.json && cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/query.py --input /tmp/test_query.json`

Expected: JSON output with success:true and empty results (no data yet)

**Step 3: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/query.py`

Run: `git commit -m "feat: implement regulation query script"`

---

## Task 6: Implement Check Script (scripts/check.py)

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/check.py`

**Step 1: Write check.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´Ÿé¢æ¸…å•æ£€æŸ¥è„šæœ¬
"""
from template import main
from lib import db

def execute(params):
    """æ‰§è¡Œè´Ÿé¢æ¸…å•æ£€æŸ¥"""
    clauses = params['clauses']

    # è·å–è´Ÿé¢æ¸…å•è§„åˆ™
    rules = db.get_negative_list()

    # æ‰§è¡Œæ£€æŸ¥
    violations = []
    for idx, clause in enumerate(clauses):
        for rule in rules:
            if match_rule(clause, rule):
                violations.append({
                    'clause_index': idx,
                    'clause_text': clause[:100] + '...' if len(clause) > 100 else clause,
                    'rule': rule['rule_number'],
                    'description': rule['description'],
                    'severity': rule['severity'],
                    'category': rule['category'],
                    'remediation': rule['remediation']
                })

    return {
        'success': True,
        'violations': violations,
        'count': len(violations),
        'summary': group_by_severity(violations)
    }

def match_rule(clause, rule):
    """è§„åˆ™åŒ¹é…é€»è¾‘"""
    # å…³é”®è¯åŒ¹é…
    keywords = rule.get('keywords', [])
    if keywords:
        import json
        keyword_list = json.loads(keywords) if isinstance(keywords, str) else keywords
        for keyword in keyword_list:
            if keyword in clause:
                return True

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
    patterns = rule.get('patterns', [])
    if patterns:
        import json
        import re
        pattern_list = json.loads(patterns) if isinstance(patterns, str) else patterns
        for pattern in pattern_list:
            if re.search(pattern, clause):
                return True

    return False

def group_by_severity(violations):
    """æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„"""
    summary = {
        'high': sum(1 for v in violations if v['severity'] == 'high'),
        'medium': sum(1 for v in violations if v['severity'] == 'medium'),
        'low': sum(1 for v in violations if v['severity'] == 'low')
    }
    return summary

if __name__ == '__main__':
    main()
```

**Step 2: Make executable and test**

Run: `chmod +x /root/.openclaw/workspace/skills/actuary-sleuth/scripts/check.py`

Run: `echo '{"clauses":["æµ‹è¯•æ¡æ¬¾å†…å®¹"]}'> /tmp/test_check.json && cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/check.py --input /tmp/test_check.json`

Expected: JSON output with success:true and empty violations (no rules yet)

**Step 3: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/check.py`

Run: `git commit -m "feat: implement negative list check script"`

---

## Task 7: Implement Remaining Scripts

### Task 7a: preprocess.py

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/preprocess.py`

**Step 1: Write preprocess.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£é¢„å¤„ç†è„šæœ¬
"""
from template import main

def execute(params):
    """æ‰§è¡Œæ–‡æ¡£é¢„å¤„ç†"""
    content = params.get('content', '')

    # ç®€å•é¢„å¤„ç†ï¼šæå–æ¡æ¬¾
    clauses = []
    sections = []
    current_section = "å‰è¨€"
    current_clauses = []

    for line in content.split('\n'):
        line = line.strip()
        if not line:
            continue

        # æ£€æµ‹ç« èŠ‚
        if line.startswith('#') or 'ç¬¬' in line and 'ç« ' in line:
            if current_clauses:
                sections.append({
                    'title': current_section,
                    'clauses': current_clauses
                })
                clauses.extend(current_clauses)
                current_clauses = []
            current_section = line.lstrip('#').strip()
        else:
            current_clauses.append(line)

    # æœ€åä¸€éƒ¨åˆ†
    if current_clauses:
        sections.append({
            'title': current_section,
            'clauses': current_clauses
        })
        clauses.extend(current_clauses)

    return {
        'success': True,
        'clauses': clauses,
        'sections': sections,
        'metadata': {
            'total_clauses': len(clauses),
            'total_sections': len(sections)
        }
    }

if __name__ == '__main__':
    main()
```

**Step 2: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/preprocess.py && git commit -m "feat: implement document preprocessing script"`

### Task 7b: scoring.py

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/scoring.py`

**Step 1: Write scoring.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯„åˆ†æ¨¡å—è„šæœ¬
"""

def calculate_score(violations, pricing=None):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    if not violations:
        return 100

    # åŸºç¡€åˆ†100
    score = 100

    # æ ¹æ®è¿è§„ä¸¥é‡ç¨‹åº¦æ‰£åˆ†
    for v in violations:
        severity = v.get('severity', 'low')
        if severity == 'high':
            score -= 20
        elif severity == 'medium':
            score -= 10
        else:
            score -= 5

    # å®šä»·åˆç†æ€§å½±å“
    if pricing and not pricing.get('reasonable', True):
        score -= 15

    return max(0, score)

def analyze_pricing(pricing_data):
    """åˆ†æå®šä»·åˆç†æ€§"""
    # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›å ä½ç»“æœ
    return {
        'reasonable': True,
        'mortality_rate': pricing_data.get('mortality', 0.001),
        'interest_rate': pricing_data.get('interest', 0.035),
        'expense_rate': pricing_data.get('expense', 0.15)
    }
```

**Step 2: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/scoring.py && git commit -m "feat: implement scoring module"`

### Task 7c: report.py

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/report.py`

**Step 1: Write report.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆè„šæœ¬
"""
from datetime import datetime
import uuid

def generate(data):
    """ç”Ÿæˆå®¡æ ¸æŠ¥å‘Š"""
    violations = data.get('violations', [])
    score = data.get('score', 0)

    # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
    report_lines = [
        "ğŸ“Š å®¡æ ¸æŠ¥å‘Š",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"ã€ç»¼åˆè¯„åˆ†ã€‘{score} åˆ† - {'åˆæ ¼' if score >= 60 else 'ä¸åˆæ ¼'}",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
    ]

    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
    high_violations = [v for v in violations if v.get('severity') == 'high']
    medium_violations = [v for v in violations if v.get('severity') == 'medium']

    if high_violations:
        report_lines.append(f"ğŸ”´ é«˜å±è¿è§„ ({len(high_violations)})")
        for idx, v in enumerate(high_violations, 1):
            report_lines.append(f"  {idx}. {v.get('description', 'æœªçŸ¥è¿è§„')}")
            report_lines.append(f"     - ä½ç½®: ç¬¬{v.get('clause_index', '?')}æ¡")
            report_lines.append(f"     - ä¸¥é‡ç¨‹åº¦: é«˜")
            report_lines.append(f"     - å»ºè®®: {v.get('remediation', 'è¯·æ•´æ”¹')}")

    if medium_violations:
        report_lines.append(f"ğŸŸ¡ ä¸­å±è¿è§„ ({len(medium_violations)})")
        for idx, v in enumerate(medium_violations, 1):
            report_lines.append(f"  {idx}. {v.get('description', 'æœªçŸ¥è¿è§„')}")

    # å®šä»·åˆ†æ
    pricing = data.get('pricing')
    if pricing:
        if pricing.get('reasonable', True):
            report_lines.append("âœ… å®šä»·åˆ†æåˆç†")
        else:
            report_lines.append("âš ï¸ å®šä»·åˆ†æéœ€å…³æ³¨")

    # å…ƒæ•°æ®
    metadata = data.get('metadata', {})
    report_lines.extend([
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"å®¡æ ¸æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"å®¡æ ¸ç¼–å·: AUD-{datetime.now().strftime('%Y%m%d')}-{uuid.uuid4().hex[:6].upper()}"
    ])

    return {
        'success': True,
        'report': '\n'.join(report_lines),
        'raw_data': data
    }
```

**Step 2: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/report.py && git commit -m "feat: implement report generation module"`

### Task 7d: audit.py

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/audit.py`

**Step 1: Write audit.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®¡æ ¸å¼•æ“ - ä¸»å…¥å£
"""
from template import main
import sys
from pathlib import Path

# æ·»åŠ  lib ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'lib'))

from lib import preprocess, check, query, scoring, report

def execute(params):
    """æ‰§è¡Œå®Œæ•´å®¡æ ¸æµç¨‹"""
    # 1. æ–‡æ¡£é¢„å¤„ç†
    doc = preprocess.execute({'content': params.get('documentContent', '')})

    # 2. è´Ÿé¢æ¸…å•æ£€æŸ¥
    violations = check.execute({'clauses': doc.get('clauses', [])})
    violation_list = violations.get('violations', [])

    # 3. æ³•è§„åˆè§„æ£€æŸ¥
    audit_type = params.get('auditType', 'full')
    if audit_type != 'negative-only':
        for v in violation_list:
            v['regulations'] = query.execute({
                'query': v['description'],
                'searchType': 'hybrid'
            })

    # 4. å®šä»·åˆ†æ
    pricing = None
    pricing_data = params.get('pricing_data')
    if pricing_data and audit_type == 'full':
        pricing = scoring.analyze_pricing(pricing_data)

    # 5. è®¡ç®—ç»¼åˆè¯„åˆ†
    score = scoring.calculate_score(violation_list, pricing)

    # 6. ç”ŸæˆæŠ¥å‘Š
    return report.generate({
        'violations': violation_list,
        'pricing': pricing,
        'score': score,
        'document': doc,
        'metadata': {
            'audit_type': audit_type,
            'document_url': params.get('documentUrl', ''),
            'timestamp': datetime.now().isoformat()
        }
    })

if __name__ == '__main__':
    from datetime import datetime
    main()
```

**Step 2: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/scripts/audit.py && git commit -m "feat: implement main audit engine script"`

---

## Task 8: Import Sample Data

**Files:**
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/scripts/import_regs.py`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/references/01_ä¿é™©æ³•ç›¸å…³ç›‘ç®¡è§„å®š.md`
- Create: `/root/.openclaw/workspace/skills/actuary-sleuth/references/02_è´Ÿé¢æ¸…å•.md`

**Step 1: Write import_regs.py**

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¼å…¥æ³•è§„æ•°æ®
"""
import sqlite3
import re
from pathlib import Path

DB_PATH = Path(__file__).parent.parent / 'data' / 'actuary.db'
REFS_PATH = Path(__file__).parent.parent / 'references'

def import_markdown_file(file_path):
    """å¯¼å…¥å•ä¸ª Markdown æ³•è§„æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    law_name = file_path.stem
    articles = parse_articles(content)

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    for article in articles:
        cur.execute('''
            INSERT OR REPLACE INTO regulations
            (id, law_name, article_number, content, category)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            f"{law_name}_{article['number']}",
            law_name,
            article['number'],
            article['content'],
            article.get('category', '')
        ))

    conn.commit()
    conn.close()
    print(f"Imported {len(articles)} articles from {file_path.name}")

def parse_articles(content):
    """è§£æ Markdown æ–‡ä»¶ä¸­çš„æ¡æ¬¾"""
    articles = []
    pattern = r'^(#{1,3}\s*)?(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡|[\d]+\.?)\s*(.*)$'

    current_article = None

    for line in content.split('\n'):
        match = re.match(pattern, line.strip())
        if match:
            if current_article:
                articles.append(current_article)
            current_article = {
                'number': match.group(2),
                'title': match.group(3),
                'content': ''
            }
        elif current_article:
            current_article['content'] += line + '\n'

    if current_article:
        articles.append(current_article)

    return articles

def import_negative_list():
    """å¯¼å…¥è´Ÿé¢æ¸…å•"""
    nl_file = REFS_PATH / '02_è´Ÿé¢æ¸…å•.md'
    with open(nl_file, 'r', encoding='utf-8') as f:
        content = f.read()

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    # ç®€åŒ–ç‰ˆï¼šæ’å…¥ç¤ºä¾‹è§„åˆ™
    sample_rules = [
        (1, 'NL001', 'å…è´£æ¡æ¬¾æœªåŠ ç²—æ ‡çº¢', 'high', 'æ ¼å¼', 'è¯·å°†å…è´£æ¡æ¬¾åŠ ç²—å¹¶ä½¿ç”¨çº¢è‰²å­—ä½“', '[]', '[]', 'v1.0', '2024-01-01'),
        (2, 'NL002', 'çŠ¹è±«æœŸæè¿°ä¸å®Œæ•´', 'high', 'å†…å®¹', 'è¡¥å……çŠ¹è±«æœŸèµ·ç®—æ—¥æœŸ', '[]', '[]', 'v1.0', '2024-01-01'),
    ]

    for rule in sample_rules:
        cur.execute('''
            INSERT OR REPLACE INTO negative_list
            (id, rule_number, description, severity, category, remediation, keywords, patterns, version, effective_date)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', rule)

    conn.commit()
    conn.close()
    print(f"Imported {len(sample_rules)} negative list rules")

if __name__ == '__main__':
    import_negative_list()
```

**Step 2: Create sample reference files**

Run: `cat > /root/.openclaw/workspace/skills/actuary-sleuth/references/01_ä¿é™©æ³•ç›¸å…³ç›‘ç®¡è§„å®š.md << 'EOF'
# ä¿é™©æ³•ç›¸å…³ç›‘ç®¡è§„å®š

## ç¬¬åå…­æ¡

è®¢ç«‹ä¿é™©åˆåŒï¼Œä¿é™©äººå°±ä¿é™©æ ‡çš„æˆ–è€…è¢«ä¿é™©äººçš„æœ‰å…³æƒ…å†µæå‡ºè¯¢é—®çš„ï¼ŒæŠ•ä¿äººåº”å½“å¦‚å®å‘ŠçŸ¥ã€‚

## ç¬¬åä¸ƒæ¡

ä¿é™©åˆåŒä¸­è§„å®šæœ‰å…³äºä¿é™©äººè´£ä»»å…é™¤æ¡æ¬¾çš„ï¼Œä¿é™©äººåœ¨è®¢ç«‹ä¿é™©åˆåŒæ—¶åº”å½“å‘æŠ•ä¿äººæ˜ç¡®è¯´æ˜ï¼Œæœªæ˜ç¡®è¯´æ˜çš„ï¼Œè¯¥æ¡æ¬¾ä¸äº§ç”Ÿæ•ˆåŠ›ã€‚

## ç¬¬åä¹æ¡

æŠ•ä¿äººå¯ä»¥è§£é™¤åˆåŒï¼Œä¿é™©äººä¸å¾—è§£é™¤åˆåŒã€‚
EOF`

Run: `cat > /root/.openclaw/workspace/skills/actuary-sleuth/references/02_è´Ÿé¢æ¸…å•.md << 'EOF'
# è´Ÿé¢æ¸…å•

## é«˜å±è¿è§„

1. å…è´£æ¡æ¬¾æœªåŠ ç²—æ ‡çº¢
2. çŠ¹è±«æœŸæè¿°ä¸å®Œæ•´
3. è´¹ç‡è¡¨ä¸æ¸…æ™°
EOF`

**Step 3: Test import**

Run: `chmod +x /root/.openclaw/workspace/skills/actuary-sleuth/scripts/import_regs.py`

Run: `cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/import_regs.py`

Expected: `Imported 2 negative list rules`

**Step 4: Verify data**

Run: `sqlite3 /root/.openclaw/workspace/skills/actuary-sleuth/data/actuary.db "SELECT COUNT(*) FROM regulations;"`

Expected: `3`

Run: `sqlite3 /root/.openclaw/workspace/skills/actuary-sleuth/data/actuary.db "SELECT COUNT(*) FROM negative_list;"`

Expected: `2`

**Step 5: Commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/`

Run: `git commit -m "feat: add sample regulation data and import script"`

---

## Task 9: Final Integration Testing

**Files:**
- Test all scripts end-to-end

**Step 1: Test query script with data**

Run: `echo '{"query":"ç¬¬åå…­æ¡"}' > /tmp/test_query_final.json && cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/query.py --input /tmp/test_query_final.json`

Expected: JSON with results containing "ç¬¬åå…­æ¡" content

**Step 2: Test check script with data**

Run: `echo '{"clauses":["ä¿é™©äººæœ‰æƒè§£é™¤åˆåŒ","çŠ¹è±«æœŸ10å¤©"]}'> /tmp/test_check_final.json && cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/check.py --input /tmp/test_check_final.json`

Expected: JSON with violations detected

**Step 3: Test full audit flow**

Run: `echo '{"documentContent":"# æµ‹è¯•ä¿é™©äº§å“\n## ç¬¬ä¸€æ¡\nä¿é™©äººæœ‰æƒè§£é™¤åˆåŒã€‚\n## ç¬¬äºŒæ¡\nçŠ¹è±«æœŸ10å¤©ã€‚"}' > /tmp/test_audit_final.json && cd /root/.openclaw/workspace/skills/actuary-sleuth && python3 scripts/audit.py --input /tmp/test_audit_final.json`

Expected: JSON report with score and violations

**Step 4: Verify all files exist and are executable**

Run: `ls -la /root/.openclaw/workspace/skills/actuary-sleuth/scripts/*.py`

Expected: All Python scripts listed with execute permissions

**Step 5: Final commit**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/ && git commit -m "test: complete integration testing and validation"`

---

## Task 10: Documentation and Cleanup

**Files:**
- Update: SKILL.md with usage examples
- Create: README.md for the skill

**Step 1: Create README.md**

```markdown
# Actuary Sleuth Skill

ä¿é™©äº§å“ç²¾ç®—å®¡æ ¸ç³»ç»Ÿï¼Œæ”¯æŒè´Ÿé¢æ¸…å•æ£€æŸ¥ã€æ³•è§„æŸ¥è¯¢å’Œå®¡æ ¸æŠ¥å‘Šç”Ÿæˆã€‚

## å®‰è£…

1. ç¡®ä¿å·²å®‰è£… Python 3.10+
2. å®‰è£…ä¾èµ–: `pip install -r scripts/requirements.txt`
3. åˆå§‹åŒ–æ•°æ®åº“: `python3 scripts/init_db.py`
4. å¯¼å…¥æ³•è§„æ•°æ®: `python3 scripts/import_regs.py`

## ä½¿ç”¨

### å®¡æ ¸æ–‡æ¡£

\`\`\`bash
echo '{"documentContent":"..."}' | python3 scripts/audit.py --input /dev/stdin
\`\`\`

### æŸ¥è¯¢æ³•è§„

\`\`\`bash
echo '{"query":"ä¿é™©æ³•ç¬¬åå…­æ¡"}' | python3 scripts/query.py --input /dev/stdin
\`\`\`

### æ£€æŸ¥è´Ÿé¢æ¸…å•

\`\`\`bash
echo '{"clauses":["..."]}' | python3 scripts/check.py --input /dev/stdin
\`\`\`
```

**Step 2: Commit documentation**

Run: `git add /root/.openclaw/workspace/skills/actuary-sleuth/ && git commit -m "docs: add usage documentation and README"`

**Step 3: Push to remote**

Run: `git push origin main`
